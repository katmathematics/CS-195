{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/katmathematics/CS-195/blob/main/F1_1_HuggingFace_Mathesius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C192SOmJS6lw"
      },
      "source": [
        "# CS 195: Natural Language Processing\n",
        "## Introduction to the Hugging Face Transformers Library\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ericmanley/f23-CS195NLP/blob/main/F1_1_HuggingFace.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLbtre1VNfxs"
      },
      "source": [
        "## References\n",
        "\n",
        "Hugging Face *Quicktour*: https://huggingface.co/docs/transformers/quicktour\n",
        "\n",
        "Hugging Face *Run Inference with Pipelines tutorial*: https://huggingface.co/docs/transformers/pipeline_tutorial\n",
        "\n",
        "Hugging Face *NLP Course, Chapter 2*: https://huggingface.co/learn/nlp-course/chapter2/1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXaQj_c4Nfxt"
      },
      "source": [
        "## What is Hugging Face?\n",
        "\n",
        "Hugging Face is a private company\n",
        "* Founded in 2016 by French entrepreneurs Clément Delangue, Julien Chaumond, and Thomas Wolf\n",
        "* Based in New York City\n",
        "\n",
        "Provide a popular free, open-source Python library called **transformers** for NLP (and other) tasks\n",
        "\n",
        "Host *hundreds of thousands of models* that you can use in your own programs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoYFPk4uNfxt"
      },
      "source": [
        "## Installing the transformers module\n",
        "\n",
        "This is my favored way of installing packages from a Jupyter Notebook\n",
        "\n",
        "If you have lots of Python distributions installed, it should use the right one\n",
        "\n",
        "It may take a few minutes, but *you should only have to do this once*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGdJr3HqNfxu",
        "outputId": "d0159531-bc96-44b4-e17d-ec8cc3f595af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.3)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "!{sys.executable} -m pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgBIUGEGNfxw"
      },
      "source": [
        "## Using the sentiment analysis pipeline\n",
        "\n",
        "**Sentiment analysis** attempts to identify the overall feeling intended by the writer of some text\n",
        "\n",
        "The creators of this model **trained** it on lots of examples of text that were labeled as either *positive* or *negative*\n",
        "\n",
        "A **pipeline** is a series of steps for performing **inference**\n",
        "* tokenize and preprocess the input text (more on this later)\n",
        "* ask the model for a prediction\n",
        "* post-process model's result and turn it into something you can use\n",
        "\n",
        "![full_nlp_pipeline.svg](https://github.com/ericmanley/f23-CS195NLP/blob/main/images/full_nlp_pipeline.svg?raw=1)\n",
        "image source: https://huggingface.co/learn/nlp-course/chapter2/2?fw=pt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Bwc46ZUNfxx"
      },
      "source": [
        "We *are* specifying the kind of task: `sentiment-analysis`\n",
        "\n",
        "We *are not* asking for a specific model, so it picks one of many it has by default\n",
        "\n",
        "The first time you do this, it will have to download the model - this can take some time depending on your network connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0_gH3o-Nfxx",
        "outputId": "871ecfcc-3e22-4db7-dacf-53e957afa8d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'NEGATIVE', 'score': 0.9993765950202942}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "#classifier(\"We are an exception among people. We belong to those who are not an integral part of humanity but exist only to teach the world some type of great lesson.\")\n",
        "classifier(\" Luckily Olli arrives there also, and he seems to know too much about everything.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_145MqvNfxy"
      },
      "source": [
        "**Test it out:** Try changing the input to get different labels/scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqSUnQ4GNfxy"
      },
      "source": [
        "## Working with batches of text\n",
        "\n",
        "To get classifications of many different examples, pass in a list of strings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXHU5a-MNfxz",
        "outputId": "b5739f1b-6f89-4542-ab73-f5f38731c6d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'POSITIVE', 'score': 0.9991173148155212}, {'label': 'NEGATIVE', 'score': 0.9557349681854248}, {'label': 'NEGATIVE', 'score': 0.9962737560272217}]\n"
          ]
        }
      ],
      "source": [
        "results = classifier([\"It's really cool that you can get classifications for a whole batch of text\",\n",
        "                      \"I wonder if the rest of the class will be this easy.\",\n",
        "                     \"Spolier alert: it won't be.\"])\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8UjTYRwNfxz"
      },
      "source": [
        "Note that the results come back as a list of dictionaries, so you can manipulate it in the normal ways."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AQayj-X_Nfxz",
        "outputId": "c5d990cd-7617-4901-96e7-169830d332cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The sentence had POSITIVE sentiment, with a score of 0.9991173148155212\n"
          ]
        }
      ],
      "source": [
        "print(\"The sentence had\",results[0][\"label\"],\"sentiment, with a score of\",results[0][\"score\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wlc0zuveNfx0"
      },
      "source": [
        "## Exercise: Specifying a model\n",
        "\n",
        "Now try asking for a specific model.\n",
        "\n",
        "Replace one line of code in your earlier example."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZgEUHLeNfx0",
        "outputId": "cd5f422b-cc39-4407-ec28-32b411f1bc0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-951ad101376f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"SamLowe/roberta-base-go_emotions\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ],
      "source": [
        "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnsG6gctNfx0"
      },
      "source": [
        "How is this model different from the first model?\n",
        "\n",
        "Create a cell in this notebook and note the differences you see"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"SamLowe/roberta-base-go_emotions\")\n",
        "\n",
        "classifier(\"We are an exception among people. We belong to those who are not an integral part of humanity but exist only to teach the world some type of great lesson.\")\n",
        "\n",
        "classifier(\"He extolled the achievements of Europe, especially in rational and logical thought, its progressive spirit, its leadership in science, and indeed its leadership on the path to freedom.\")\n",
        "\n",
        "classifier(\"The Russian government saw his ideas as dangerous and unsound.\")\n",
        "\n",
        "classifier(\" Luckily Olli arrives there also, and he seems to know too much about everything.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-GigSw5VTNA",
        "outputId": "37e7f213-5d1a-42a4-e419-d039b7c051d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'neutral', 'score': 0.5005195140838623}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuDtszj0Nfx0"
      },
      "source": [
        "## Applied Exploration\n",
        "\n",
        "The `roberta-base-go_emotions` model is documented here: https://huggingface.co/SamLowe/roberta-base-go_emotions\n",
        "\n",
        "Answer some questions about this:\n",
        "* What is `roberta-base`? Write down some things you can learn about it from the documentation.\n",
        "* What is `go_emotions`? Write down some things you can learn about it from the documentation.\n",
        "\n",
        "Go to the Hugging Face models page: https://huggingface.co/models\n",
        "* click `Text Classification`\n",
        "* Try some additional models\n",
        "    - test out at least one more sentiment/emotions model\n",
        "    - test out at least two other kinds of models - like news topic classification or spam detection\n",
        "    - write down some info about the models you found\n",
        "        - what is it for?\n",
        "        - who made it?\n",
        "        - what kind of data was it trained on?\n",
        "        - are they based on some other model and trained on new data (*fine-tuned*) for a specific task?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is roberta-base?\n",
        "\n",
        "roberta-base is an English language sentiment analysis model. The model was introduced in a 2019 paper by Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. The model was trained on raw, unlabeled texts using masked language modeling. The model, while usable in its base form, is intended to be further refined for specific use cases.\n",
        "\n",
        "## What is go_emotions?\n",
        "\n",
        "Go_emotions is a dataset of 58,000 reddit comments that have each been categorized as having 1 of 27 possible emotions."
      ],
      "metadata": {
        "id": "79e6T2NpcF8x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Sentimenet Analysis\n",
        "\n",
        "### Model: [rubert-tiny2-russian-sentiment](https://huggingface.co/seara/rubert-tiny2-russian-sentiment)\n",
        "### Author: [seara](https://huggingface.co/seara)\n",
        "\n"
      ],
      "metadata": {
        "id": "d9AAW7g8cSpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Russian text example\n",
        "# Classifier Source: https://huggingface.co/seara/rubert-tiny2-russian-sentiment\n",
        "from transformers import pipeline\n",
        "\n",
        "quotes = []\n",
        "philosophers = []\n",
        "\n",
        "philosophers.append(\"Чаадаев\")\n",
        "quotes.append(\"тусклое и мрачное существование, лишённое силы и энергии, которое ничто не оживляло, кроме злодеяний, ничто не смягчало, кроме рабства. Ни пленительных воспоминаний, ни грациозных образов в памяти народа, ни мощных поучений в его предании… Мы живём одним настоящим, в самых тесных его пределах, без прошедшего и будущего, среди мёртвого застоя.\")\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"seara/rubert-tiny2-russian-sentiment\")\n",
        "\n",
        "results = classifier(quotes)\n",
        "\n",
        "for idx in range(len(results)):\n",
        "  print(philosophers[idx] + \"\\'s writing is \" + results[idx][\"label\"] + \".\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xncfTKHWyP2",
        "outputId": "d3dfb8a4-c26c-48e5-aa4a-8a8f5cad4bd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Чаадаев's writing is negative.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Further Analysis"
      ],
      "metadata": {
        "id": "bQnIpxqeeAQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!{sys.executable} huggingface-cli login token = \"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\"\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\", model=\"kearney/infoquality\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "id": "eF8Q-zmzf71m",
        "outputId": "d5ff52b5-e4ce-4554-b6e6-7395e543c017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: {sys.executable}: command not found\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-444fc975a859>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{sys.executable} huggingface-cli login token = \"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\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sentiment-analysis\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"kearney/infoquality\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}